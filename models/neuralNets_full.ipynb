{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>459</th>\n",
       "      <th>460</th>\n",
       "      <th>461</th>\n",
       "      <th>462</th>\n",
       "      <th>463</th>\n",
       "      <th>464</th>\n",
       "      <th>465</th>\n",
       "      <th>466</th>\n",
       "      <th>467</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156041</td>\n",
       "      <td>0.034724</td>\n",
       "      <td>0.071444</td>\n",
       "      <td>0.078117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043656</td>\n",
       "      <td>0.147673</td>\n",
       "      <td>0.290654</td>\n",
       "      <td>0.227140</td>\n",
       "      <td>0.271585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063550</td>\n",
       "      <td>0.104668</td>\n",
       "      <td>0.057380</td>\n",
       "      <td>0.062866</td>\n",
       "      <td>0.189442</td>\n",
       "      <td>0.170856</td>\n",
       "      <td>0.159821</td>\n",
       "      <td>0.323322</td>\n",
       "      <td>0.348375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.099105</td>\n",
       "      <td>0.033467</td>\n",
       "      <td>0.048210</td>\n",
       "      <td>0.096153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050459</td>\n",
       "      <td>0.181863</td>\n",
       "      <td>0.332776</td>\n",
       "      <td>0.276899</td>\n",
       "      <td>0.323902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061139</td>\n",
       "      <td>0.101462</td>\n",
       "      <td>0.051161</td>\n",
       "      <td>0.050882</td>\n",
       "      <td>0.230257</td>\n",
       "      <td>0.214284</td>\n",
       "      <td>0.201468</td>\n",
       "      <td>0.353529</td>\n",
       "      <td>0.377521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160259</td>\n",
       "      <td>0.033538</td>\n",
       "      <td>0.105772</td>\n",
       "      <td>0.086060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046421</td>\n",
       "      <td>0.181095</td>\n",
       "      <td>0.224147</td>\n",
       "      <td>0.273403</td>\n",
       "      <td>0.312137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071666</td>\n",
       "      <td>0.147298</td>\n",
       "      <td>0.067166</td>\n",
       "      <td>0.087085</td>\n",
       "      <td>0.274896</td>\n",
       "      <td>0.251641</td>\n",
       "      <td>0.229446</td>\n",
       "      <td>0.382837</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.139705</td>\n",
       "      <td>0.035719</td>\n",
       "      <td>0.060722</td>\n",
       "      <td>0.098022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051891</td>\n",
       "      <td>0.187796</td>\n",
       "      <td>0.330197</td>\n",
       "      <td>0.296981</td>\n",
       "      <td>0.350095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063510</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.055346</td>\n",
       "      <td>0.057549</td>\n",
       "      <td>0.232088</td>\n",
       "      <td>0.215398</td>\n",
       "      <td>0.203230</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>0.383226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144930</td>\n",
       "      <td>0.030739</td>\n",
       "      <td>0.065995</td>\n",
       "      <td>0.082237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041594</td>\n",
       "      <td>0.145923</td>\n",
       "      <td>0.312308</td>\n",
       "      <td>0.210267</td>\n",
       "      <td>0.247076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>0.051338</td>\n",
       "      <td>0.042271</td>\n",
       "      <td>0.047047</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.146428</td>\n",
       "      <td>0.139789</td>\n",
       "      <td>0.194182</td>\n",
       "      <td>0.204608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 469 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3    4         5         6         7  \\\n",
       "0  0.156041  0.034724  0.071444  0.078117  0.0  0.043656  0.147673  0.290654   \n",
       "1  0.099105  0.033467  0.048210  0.096153  0.0  0.050459  0.181863  0.332776   \n",
       "2  0.160259  0.033538  0.105772  0.086060  0.0  0.046421  0.181095  0.224147   \n",
       "3  0.139705  0.035719  0.060722  0.098022  0.0  0.051891  0.187796  0.330197   \n",
       "4  0.144930  0.030739  0.065995  0.082237  0.0  0.041594  0.145923  0.312308   \n",
       "\n",
       "          8         9  ...       459       460       461       462       463  \\\n",
       "0  0.227140  0.271585  ...  0.063550  0.104668  0.057380  0.062866  0.189442   \n",
       "1  0.276899  0.323902  ...  0.061139  0.101462  0.051161  0.050882  0.230257   \n",
       "2  0.273403  0.312137  ...  0.071666  0.147298  0.067166  0.087085  0.274896   \n",
       "3  0.296981  0.350095  ...  0.063510  0.106100  0.055346  0.057549  0.232088   \n",
       "4  0.210267  0.247076  ...  0.035856  0.051338  0.042271  0.047047  0.154600   \n",
       "\n",
       "        464       465       466       467  label  \n",
       "0  0.170856  0.159821  0.323322  0.348375      0  \n",
       "1  0.214284  0.201468  0.353529  0.377521      0  \n",
       "2  0.251641  0.229446  0.382837  0.408696      0  \n",
       "3  0.215398  0.203230  0.354787  0.383226      0  \n",
       "4  0.146428  0.139789  0.194182  0.204608      0  \n",
       "\n",
       "[5 rows x 469 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data.csv')\n",
    "data.drop('Index', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split variables from label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 468)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               60032     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,318\n",
      "Trainable params: 77,318\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape = 468)\n",
    "\n",
    "z = layers.Dense(128, activation=\"relu\")(inputs)\n",
    "z = layers.Dense(128, activation=\"relu\")(z)\n",
    "outputs = layers.Dense(6, activation=\"softmax\")(z)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.6992 - acc: 0.2969\n",
      "Epoch 2/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.5523 - acc: 0.3855\n",
      "Epoch 3/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.4582 - acc: 0.4314\n",
      "Epoch 4/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.4429 - acc: 0.4340\n",
      "Epoch 5/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.4005 - acc: 0.4501\n",
      "Epoch 6/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.3889 - acc: 0.4548\n",
      "Epoch 7/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.3717 - acc: 0.4608\n",
      "Epoch 8/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.3654 - acc: 0.4627\n",
      "Epoch 9/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.3562 - acc: 0.4650\n",
      "Epoch 10/100\n",
      "407/407 [==============================] - 2s 4ms/step - loss: 1.3400 - acc: 0.4716\n",
      "Epoch 11/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.3386 - acc: 0.4732\n",
      "Epoch 12/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.3310 - acc: 0.4776\n",
      "Epoch 13/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.3331 - acc: 0.4759\n",
      "Epoch 14/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.3226 - acc: 0.4773\n",
      "Epoch 15/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.3151 - acc: 0.4807\n",
      "Epoch 16/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.3238 - acc: 0.4803\n",
      "Epoch 17/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.3127 - acc: 0.4840\n",
      "Epoch 18/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.3152 - acc: 0.4792\n",
      "Epoch 19/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.3075 - acc: 0.4837\n",
      "Epoch 20/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.3068 - acc: 0.4860\n",
      "Epoch 21/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.3054 - acc: 0.4841\n",
      "Epoch 22/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2982 - acc: 0.4875\n",
      "Epoch 23/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2990 - acc: 0.4882\n",
      "Epoch 24/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2955 - acc: 0.4885\n",
      "Epoch 25/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2962 - acc: 0.4902\n",
      "Epoch 26/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2943 - acc: 0.4937\n",
      "Epoch 27/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2804 - acc: 0.4939\n",
      "Epoch 28/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2927 - acc: 0.4886\n",
      "Epoch 29/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2840 - acc: 0.4958\n",
      "Epoch 30/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2818 - acc: 0.4934\n",
      "Epoch 31/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2790 - acc: 0.4967\n",
      "Epoch 32/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2863 - acc: 0.4923\n",
      "Epoch 33/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2886 - acc: 0.4911\n",
      "Epoch 34/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2725 - acc: 0.4974\n",
      "Epoch 35/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2809 - acc: 0.4916\n",
      "Epoch 36/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2726 - acc: 0.4959\n",
      "Epoch 37/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2803 - acc: 0.4962\n",
      "Epoch 38/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2672 - acc: 0.5006\n",
      "Epoch 39/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2639 - acc: 0.5011\n",
      "Epoch 40/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2699 - acc: 0.4979\n",
      "Epoch 41/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2624 - acc: 0.5032\n",
      "Epoch 42/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2700 - acc: 0.4984\n",
      "Epoch 43/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2696 - acc: 0.4972\n",
      "Epoch 44/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2619 - acc: 0.5040\n",
      "Epoch 45/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2619 - acc: 0.5028\n",
      "Epoch 46/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2660 - acc: 0.4983\n",
      "Epoch 47/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2574 - acc: 0.5058\n",
      "Epoch 48/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2548 - acc: 0.5042\n",
      "Epoch 49/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2517 - acc: 0.5059\n",
      "Epoch 50/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2559 - acc: 0.5045\n",
      "Epoch 51/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2606 - acc: 0.5032\n",
      "Epoch 52/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2588 - acc: 0.5050\n",
      "Epoch 53/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2542 - acc: 0.5057\n",
      "Epoch 54/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2597 - acc: 0.5035\n",
      "Epoch 55/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2468 - acc: 0.5082\n",
      "Epoch 56/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2475 - acc: 0.5087\n",
      "Epoch 57/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2456 - acc: 0.5087\n",
      "Epoch 58/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2419 - acc: 0.5112\n",
      "Epoch 59/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2425 - acc: 0.5077\n",
      "Epoch 60/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2523 - acc: 0.5052\n",
      "Epoch 61/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2472 - acc: 0.5104\n",
      "Epoch 62/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2445 - acc: 0.5075\n",
      "Epoch 63/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2442 - acc: 0.5092\n",
      "Epoch 64/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2401 - acc: 0.5130\n",
      "Epoch 65/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2451 - acc: 0.5098\n",
      "Epoch 66/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2426 - acc: 0.5102\n",
      "Epoch 67/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2375 - acc: 0.5115\n",
      "Epoch 68/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2425 - acc: 0.5082\n",
      "Epoch 69/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2406 - acc: 0.5082\n",
      "Epoch 70/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2369 - acc: 0.5145\n",
      "Epoch 71/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2314 - acc: 0.5148\n",
      "Epoch 72/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2422 - acc: 0.5080\n",
      "Epoch 73/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2336 - acc: 0.5103\n",
      "Epoch 74/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2311 - acc: 0.5146\n",
      "Epoch 75/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2353 - acc: 0.5132\n",
      "Epoch 76/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2277 - acc: 0.5166\n",
      "Epoch 77/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2361 - acc: 0.5098\n",
      "Epoch 78/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2303 - acc: 0.5149\n",
      "Epoch 79/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2214 - acc: 0.5198\n",
      "Epoch 80/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2266 - acc: 0.5192\n",
      "Epoch 81/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2269 - acc: 0.5169\n",
      "Epoch 82/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2241 - acc: 0.5191\n",
      "Epoch 83/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2254 - acc: 0.5165\n",
      "Epoch 84/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2235 - acc: 0.5150\n",
      "Epoch 85/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2212 - acc: 0.5185\n",
      "Epoch 86/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2193 - acc: 0.5186\n",
      "Epoch 87/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2240 - acc: 0.5183\n",
      "Epoch 88/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2133 - acc: 0.5188\n",
      "Epoch 89/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2286 - acc: 0.5141\n",
      "Epoch 90/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2289 - acc: 0.5142\n",
      "Epoch 91/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2197 - acc: 0.5174\n",
      "Epoch 92/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2207 - acc: 0.5164\n",
      "Epoch 93/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2174 - acc: 0.5191\n",
      "Epoch 94/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2189 - acc: 0.5185\n",
      "Epoch 95/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.2269 - acc: 0.5175\n",
      "Epoch 96/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2179 - acc: 0.5198\n",
      "Epoch 97/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2147 - acc: 0.5212\n",
      "Epoch 98/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2101 - acc: 0.5222\n",
      "Epoch 99/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2141 - acc: 0.5210\n",
      "Epoch 100/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.2091 - acc: 0.5233\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "# Train the model for 1 epoch from Numpy data\n",
    "batch_size = 64\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions = keras.backend.argmax(\n",
    "    predictions,\n",
    "    axis=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5163076923076924"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edd308e7c007ad85b362a562bfbc8a6438bc8604a7d190cd1423250b5323680b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('faces': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
