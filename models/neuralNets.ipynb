{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>7</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>17</th>\n",
       "      <th>33</th>\n",
       "      <th>37</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>46</th>\n",
       "      <th>...</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>390</th>\n",
       "      <th>398</th>\n",
       "      <th>402</th>\n",
       "      <th>405</th>\n",
       "      <th>409</th>\n",
       "      <th>415</th>\n",
       "      <th>466</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156041</td>\n",
       "      <td>0.290654</td>\n",
       "      <td>0.199809</td>\n",
       "      <td>0.290295</td>\n",
       "      <td>0.356657</td>\n",
       "      <td>0.307132</td>\n",
       "      <td>0.157192</td>\n",
       "      <td>0.187702</td>\n",
       "      <td>0.217832</td>\n",
       "      <td>0.374565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309477</td>\n",
       "      <td>0.318458</td>\n",
       "      <td>0.295038</td>\n",
       "      <td>0.212476</td>\n",
       "      <td>0.284568</td>\n",
       "      <td>0.338188</td>\n",
       "      <td>0.244253</td>\n",
       "      <td>0.234073</td>\n",
       "      <td>0.323322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.099105</td>\n",
       "      <td>0.332776</td>\n",
       "      <td>0.119696</td>\n",
       "      <td>0.208098</td>\n",
       "      <td>0.258650</td>\n",
       "      <td>0.352134</td>\n",
       "      <td>0.101318</td>\n",
       "      <td>0.130601</td>\n",
       "      <td>0.152025</td>\n",
       "      <td>0.427157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343032</td>\n",
       "      <td>0.350165</td>\n",
       "      <td>0.319125</td>\n",
       "      <td>0.251888</td>\n",
       "      <td>0.207328</td>\n",
       "      <td>0.249380</td>\n",
       "      <td>0.196100</td>\n",
       "      <td>0.174136</td>\n",
       "      <td>0.353529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160259</td>\n",
       "      <td>0.224147</td>\n",
       "      <td>0.209884</td>\n",
       "      <td>0.213498</td>\n",
       "      <td>0.264495</td>\n",
       "      <td>0.233589</td>\n",
       "      <td>0.151807</td>\n",
       "      <td>0.161886</td>\n",
       "      <td>0.180539</td>\n",
       "      <td>0.275579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364269</td>\n",
       "      <td>0.375077</td>\n",
       "      <td>0.351450</td>\n",
       "      <td>0.293468</td>\n",
       "      <td>0.241386</td>\n",
       "      <td>0.285400</td>\n",
       "      <td>0.268769</td>\n",
       "      <td>0.265217</td>\n",
       "      <td>0.382837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.139705</td>\n",
       "      <td>0.330197</td>\n",
       "      <td>0.172731</td>\n",
       "      <td>0.188332</td>\n",
       "      <td>0.243490</td>\n",
       "      <td>0.348977</td>\n",
       "      <td>0.137025</td>\n",
       "      <td>0.159584</td>\n",
       "      <td>0.179181</td>\n",
       "      <td>0.438886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341322</td>\n",
       "      <td>0.349891</td>\n",
       "      <td>0.321454</td>\n",
       "      <td>0.252637</td>\n",
       "      <td>0.197635</td>\n",
       "      <td>0.243881</td>\n",
       "      <td>0.215141</td>\n",
       "      <td>0.200392</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144930</td>\n",
       "      <td>0.312308</td>\n",
       "      <td>0.172522</td>\n",
       "      <td>0.174161</td>\n",
       "      <td>0.215116</td>\n",
       "      <td>0.328316</td>\n",
       "      <td>0.152421</td>\n",
       "      <td>0.181887</td>\n",
       "      <td>0.210446</td>\n",
       "      <td>0.382999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.195961</td>\n",
       "      <td>0.176641</td>\n",
       "      <td>0.165296</td>\n",
       "      <td>0.164141</td>\n",
       "      <td>0.196522</td>\n",
       "      <td>0.158438</td>\n",
       "      <td>0.156289</td>\n",
       "      <td>0.194182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         7        13        14        17        33        37  \\\n",
       "0  0.156041  0.290654  0.199809  0.290295  0.356657  0.307132  0.157192   \n",
       "1  0.099105  0.332776  0.119696  0.208098  0.258650  0.352134  0.101318   \n",
       "2  0.160259  0.224147  0.209884  0.213498  0.264495  0.233589  0.151807   \n",
       "3  0.139705  0.330197  0.172731  0.188332  0.243490  0.348977  0.137025   \n",
       "4  0.144930  0.312308  0.172522  0.174161  0.215116  0.328316  0.152421   \n",
       "\n",
       "         39        40        46  ...       387       388       390       398  \\\n",
       "0  0.187702  0.217832  0.374565  ...  0.309477  0.318458  0.295038  0.212476   \n",
       "1  0.130601  0.152025  0.427157  ...  0.343032  0.350165  0.319125  0.251888   \n",
       "2  0.161886  0.180539  0.275579  ...  0.364269  0.375077  0.351450  0.293468   \n",
       "3  0.159584  0.179181  0.438886  ...  0.341322  0.349891  0.321454  0.252637   \n",
       "4  0.181887  0.210446  0.382999  ...  0.197266  0.195961  0.176641  0.165296   \n",
       "\n",
       "        402       405       409       415       466  labels  \n",
       "0  0.284568  0.338188  0.244253  0.234073  0.323322       0  \n",
       "1  0.207328  0.249380  0.196100  0.174136  0.353529       0  \n",
       "2  0.241386  0.285400  0.268769  0.265217  0.382837       0  \n",
       "3  0.197635  0.243881  0.215141  0.200392  0.354787       0  \n",
       "4  0.164141  0.196522  0.158438  0.156289  0.194182       0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../reduced.csv')\n",
    "data.drop('Index', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split variables from label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 92)]              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               11904     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,190\n",
      "Trainable params: 29,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape = 92)\n",
    "\n",
    "z = layers.Dense(128, activation=\"relu\")(inputs)\n",
    "z = layers.Dense(128, activation=\"relu\")(z)\n",
    "outputs = layers.Dense(6, activation=\"softmax\")(z)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.5958 - acc: 0.3684\n",
      "Epoch 2/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.5183 - acc: 0.4020\n",
      "Epoch 3/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.4826 - acc: 0.4140\n",
      "Epoch 4/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.4459 - acc: 0.4290\n",
      "Epoch 5/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.4324 - acc: 0.4298\n",
      "Epoch 6/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.4108 - acc: 0.4426\n",
      "Epoch 7/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3902 - acc: 0.4507\n",
      "Epoch 8/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3916 - acc: 0.4532\n",
      "Epoch 9/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3762 - acc: 0.4590\n",
      "Epoch 10/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3754 - acc: 0.4592\n",
      "Epoch 11/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3683 - acc: 0.4657\n",
      "Epoch 12/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3571 - acc: 0.4683\n",
      "Epoch 13/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3567 - acc: 0.4692\n",
      "Epoch 14/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3534 - acc: 0.4688\n",
      "Epoch 15/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3497 - acc: 0.4723\n",
      "Epoch 16/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3542 - acc: 0.4684\n",
      "Epoch 17/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3410 - acc: 0.4726\n",
      "Epoch 18/100\n",
      "407/407 [==============================] - 1s 1ms/step - loss: 1.3472 - acc: 0.4707\n",
      "Epoch 19/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3405 - acc: 0.4762\n",
      "Epoch 20/100\n",
      "407/407 [==============================] - 1s 2ms/step - loss: 1.3388 - acc: 0.4762\n",
      "Epoch 21/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3308 - acc: 0.4801\n",
      "Epoch 22/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3342 - acc: 0.4782\n",
      "Epoch 23/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3277 - acc: 0.4798\n",
      "Epoch 24/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3257 - acc: 0.4792\n",
      "Epoch 25/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3280 - acc: 0.4794\n",
      "Epoch 26/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3261 - acc: 0.4816\n",
      "Epoch 27/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3251 - acc: 0.4836\n",
      "Epoch 28/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3267 - acc: 0.4849\n",
      "Epoch 29/100\n",
      "407/407 [==============================] - 0s 941us/step - loss: 1.3204 - acc: 0.4840\n",
      "Epoch 30/100\n",
      "407/407 [==============================] - 0s 993us/step - loss: 1.3171 - acc: 0.4850\n",
      "Epoch 31/100\n",
      "407/407 [==============================] - 0s 968us/step - loss: 1.3185 - acc: 0.4867\n",
      "Epoch 32/100\n",
      "407/407 [==============================] - 0s 964us/step - loss: 1.3138 - acc: 0.4870\n",
      "Epoch 33/100\n",
      "407/407 [==============================] - 0s 956us/step - loss: 1.3150 - acc: 0.4862\n",
      "Epoch 34/100\n",
      "407/407 [==============================] - 0s 944us/step - loss: 1.3155 - acc: 0.4839\n",
      "Epoch 35/100\n",
      "407/407 [==============================] - 0s 960us/step - loss: 1.3106 - acc: 0.4884\n",
      "Epoch 36/100\n",
      "407/407 [==============================] - 0s 957us/step - loss: 1.3109 - acc: 0.4880\n",
      "Epoch 37/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.3037 - acc: 0.4930\n",
      "Epoch 38/100\n",
      "407/407 [==============================] - 0s 987us/step - loss: 1.3099 - acc: 0.4878\n",
      "Epoch 39/100\n",
      "407/407 [==============================] - 0s 956us/step - loss: 1.3048 - acc: 0.4927\n",
      "Epoch 40/100\n",
      "407/407 [==============================] - 0s 953us/step - loss: 1.3042 - acc: 0.4886\n",
      "Epoch 41/100\n",
      "407/407 [==============================] - 0s 955us/step - loss: 1.3025 - acc: 0.4890\n",
      "Epoch 42/100\n",
      "407/407 [==============================] - 0s 971us/step - loss: 1.3018 - acc: 0.4894\n",
      "Epoch 43/100\n",
      "407/407 [==============================] - 0s 992us/step - loss: 1.2937 - acc: 0.4967\n",
      "Epoch 44/100\n",
      "407/407 [==============================] - 0s 958us/step - loss: 1.2953 - acc: 0.4955\n",
      "Epoch 45/100\n",
      "407/407 [==============================] - 0s 950us/step - loss: 1.2986 - acc: 0.4919\n",
      "Epoch 46/100\n",
      "407/407 [==============================] - 0s 950us/step - loss: 1.2953 - acc: 0.4952\n",
      "Epoch 47/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2957 - acc: 0.4950\n",
      "Epoch 48/100\n",
      "407/407 [==============================] - 0s 952us/step - loss: 1.2928 - acc: 0.4952\n",
      "Epoch 49/100\n",
      "407/407 [==============================] - 0s 955us/step - loss: 1.2883 - acc: 0.4954\n",
      "Epoch 50/100\n",
      "407/407 [==============================] - 0s 958us/step - loss: 1.2901 - acc: 0.4956\n",
      "Epoch 51/100\n",
      "407/407 [==============================] - 0s 956us/step - loss: 1.2875 - acc: 0.4982\n",
      "Epoch 52/100\n",
      "407/407 [==============================] - 0s 950us/step - loss: 1.2864 - acc: 0.4978\n",
      "Epoch 53/100\n",
      "407/407 [==============================] - 0s 959us/step - loss: 1.2871 - acc: 0.4957\n",
      "Epoch 54/100\n",
      "407/407 [==============================] - 0s 962us/step - loss: 1.2885 - acc: 0.5010\n",
      "Epoch 55/100\n",
      "407/407 [==============================] - 0s 953us/step - loss: 1.2779 - acc: 0.5017\n",
      "Epoch 56/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2825 - acc: 0.5001\n",
      "Epoch 57/100\n",
      "407/407 [==============================] - 0s 950us/step - loss: 1.2807 - acc: 0.5005\n",
      "Epoch 58/100\n",
      "407/407 [==============================] - 0s 969us/step - loss: 1.2860 - acc: 0.4971\n",
      "Epoch 59/100\n",
      "407/407 [==============================] - 0s 956us/step - loss: 1.2893 - acc: 0.4987\n",
      "Epoch 60/100\n",
      "407/407 [==============================] - 0s 952us/step - loss: 1.2804 - acc: 0.4998\n",
      "Epoch 61/100\n",
      "407/407 [==============================] - 0s 954us/step - loss: 1.2808 - acc: 0.5007\n",
      "Epoch 62/100\n",
      "407/407 [==============================] - 0s 949us/step - loss: 1.2833 - acc: 0.4968\n",
      "Epoch 63/100\n",
      "407/407 [==============================] - 0s 953us/step - loss: 1.2727 - acc: 0.5030\n",
      "Epoch 64/100\n",
      "407/407 [==============================] - 0s 970us/step - loss: 1.2805 - acc: 0.5001\n",
      "Epoch 65/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2720 - acc: 0.5032\n",
      "Epoch 66/100\n",
      "407/407 [==============================] - 0s 972us/step - loss: 1.2730 - acc: 0.5023\n",
      "Epoch 67/100\n",
      "407/407 [==============================] - 0s 951us/step - loss: 1.2749 - acc: 0.5031\n",
      "Epoch 68/100\n",
      "407/407 [==============================] - 0s 976us/step - loss: 1.2754 - acc: 0.5030\n",
      "Epoch 69/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2786 - acc: 0.5006\n",
      "Epoch 70/100\n",
      "407/407 [==============================] - 0s 950us/step - loss: 1.2685 - acc: 0.5055\n",
      "Epoch 71/100\n",
      "407/407 [==============================] - 0s 968us/step - loss: 1.2705 - acc: 0.5055\n",
      "Epoch 72/100\n",
      "407/407 [==============================] - 0s 968us/step - loss: 1.2669 - acc: 0.5038\n",
      "Epoch 73/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2674 - acc: 0.5056\n",
      "Epoch 74/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2691 - acc: 0.5029\n",
      "Epoch 75/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2667 - acc: 0.5038\n",
      "Epoch 76/100\n",
      "407/407 [==============================] - 0s 984us/step - loss: 1.2651 - acc: 0.5057\n",
      "Epoch 77/100\n",
      "407/407 [==============================] - 0s 956us/step - loss: 1.2616 - acc: 0.5077\n",
      "Epoch 78/100\n",
      "407/407 [==============================] - 0s 947us/step - loss: 1.2638 - acc: 0.5069\n",
      "Epoch 79/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2655 - acc: 0.5068\n",
      "Epoch 80/100\n",
      "407/407 [==============================] - 0s 962us/step - loss: 1.2614 - acc: 0.5089\n",
      "Epoch 81/100\n",
      "407/407 [==============================] - 0s 980us/step - loss: 1.2660 - acc: 0.5039\n",
      "Epoch 82/100\n",
      "407/407 [==============================] - 0s 957us/step - loss: 1.2651 - acc: 0.5065\n",
      "Epoch 83/100\n",
      "407/407 [==============================] - 0s 973us/step - loss: 1.2647 - acc: 0.5048\n",
      "Epoch 84/100\n",
      "407/407 [==============================] - 0s 988us/step - loss: 1.2574 - acc: 0.5080\n",
      "Epoch 85/100\n",
      "407/407 [==============================] - 0s 971us/step - loss: 1.2570 - acc: 0.5072\n",
      "Epoch 86/100\n",
      "407/407 [==============================] - 0s 946us/step - loss: 1.2612 - acc: 0.5045\n",
      "Epoch 87/100\n",
      "407/407 [==============================] - 0s 954us/step - loss: 1.2534 - acc: 0.5088\n",
      "Epoch 88/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2570 - acc: 0.5089\n",
      "Epoch 89/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2573 - acc: 0.5084\n",
      "Epoch 90/100\n",
      "407/407 [==============================] - 0s 983us/step - loss: 1.2590 - acc: 0.5085\n",
      "Epoch 91/100\n",
      "407/407 [==============================] - 0s 978us/step - loss: 1.2579 - acc: 0.5088\n",
      "Epoch 92/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2608 - acc: 0.5065\n",
      "Epoch 93/100\n",
      "407/407 [==============================] - 0s 975us/step - loss: 1.2558 - acc: 0.5087\n",
      "Epoch 94/100\n",
      "407/407 [==============================] - 0s 992us/step - loss: 1.2564 - acc: 0.5088\n",
      "Epoch 95/100\n",
      "407/407 [==============================] - 0s 975us/step - loss: 1.2606 - acc: 0.5077\n",
      "Epoch 96/100\n",
      "407/407 [==============================] - 0s 985us/step - loss: 1.2486 - acc: 0.5124\n",
      "Epoch 97/100\n",
      "407/407 [==============================] - 0s 972us/step - loss: 1.2551 - acc: 0.5103\n",
      "Epoch 98/100\n",
      "407/407 [==============================] - 0s 988us/step - loss: 1.2501 - acc: 0.5085\n",
      "Epoch 99/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2512 - acc: 0.5116\n",
      "Epoch 100/100\n",
      "407/407 [==============================] - 0s 1ms/step - loss: 1.2461 - acc: 0.5139\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "# Train the model for 1 epoch from Numpy data\n",
    "batch_size = 64\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions = keras.backend.argmax(\n",
    "    predictions,\n",
    "    axis=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5095384615384615"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edd308e7c007ad85b362a562bfbc8a6438bc8604a7d190cd1423250b5323680b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('faces': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
