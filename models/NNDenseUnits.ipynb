{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>7</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>17</th>\n",
       "      <th>33</th>\n",
       "      <th>37</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>46</th>\n",
       "      <th>...</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>390</th>\n",
       "      <th>398</th>\n",
       "      <th>402</th>\n",
       "      <th>405</th>\n",
       "      <th>409</th>\n",
       "      <th>415</th>\n",
       "      <th>466</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156041</td>\n",
       "      <td>0.290654</td>\n",
       "      <td>0.199809</td>\n",
       "      <td>0.290295</td>\n",
       "      <td>0.356657</td>\n",
       "      <td>0.307132</td>\n",
       "      <td>0.157192</td>\n",
       "      <td>0.187702</td>\n",
       "      <td>0.217832</td>\n",
       "      <td>0.374565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309477</td>\n",
       "      <td>0.318458</td>\n",
       "      <td>0.295038</td>\n",
       "      <td>0.212476</td>\n",
       "      <td>0.284568</td>\n",
       "      <td>0.338188</td>\n",
       "      <td>0.244253</td>\n",
       "      <td>0.234073</td>\n",
       "      <td>0.323322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.099105</td>\n",
       "      <td>0.332776</td>\n",
       "      <td>0.119696</td>\n",
       "      <td>0.208098</td>\n",
       "      <td>0.258650</td>\n",
       "      <td>0.352134</td>\n",
       "      <td>0.101318</td>\n",
       "      <td>0.130601</td>\n",
       "      <td>0.152025</td>\n",
       "      <td>0.427157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343032</td>\n",
       "      <td>0.350165</td>\n",
       "      <td>0.319125</td>\n",
       "      <td>0.251888</td>\n",
       "      <td>0.207328</td>\n",
       "      <td>0.249380</td>\n",
       "      <td>0.196100</td>\n",
       "      <td>0.174136</td>\n",
       "      <td>0.353529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.160259</td>\n",
       "      <td>0.224147</td>\n",
       "      <td>0.209884</td>\n",
       "      <td>0.213498</td>\n",
       "      <td>0.264495</td>\n",
       "      <td>0.233589</td>\n",
       "      <td>0.151807</td>\n",
       "      <td>0.161886</td>\n",
       "      <td>0.180539</td>\n",
       "      <td>0.275579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364269</td>\n",
       "      <td>0.375077</td>\n",
       "      <td>0.351450</td>\n",
       "      <td>0.293468</td>\n",
       "      <td>0.241386</td>\n",
       "      <td>0.285400</td>\n",
       "      <td>0.268769</td>\n",
       "      <td>0.265217</td>\n",
       "      <td>0.382837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.139705</td>\n",
       "      <td>0.330197</td>\n",
       "      <td>0.172731</td>\n",
       "      <td>0.188332</td>\n",
       "      <td>0.243490</td>\n",
       "      <td>0.348977</td>\n",
       "      <td>0.137025</td>\n",
       "      <td>0.159584</td>\n",
       "      <td>0.179181</td>\n",
       "      <td>0.438886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341322</td>\n",
       "      <td>0.349891</td>\n",
       "      <td>0.321454</td>\n",
       "      <td>0.252637</td>\n",
       "      <td>0.197635</td>\n",
       "      <td>0.243881</td>\n",
       "      <td>0.215141</td>\n",
       "      <td>0.200392</td>\n",
       "      <td>0.354787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144930</td>\n",
       "      <td>0.312308</td>\n",
       "      <td>0.172522</td>\n",
       "      <td>0.174161</td>\n",
       "      <td>0.215116</td>\n",
       "      <td>0.328316</td>\n",
       "      <td>0.152421</td>\n",
       "      <td>0.181887</td>\n",
       "      <td>0.210446</td>\n",
       "      <td>0.382999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.195961</td>\n",
       "      <td>0.176641</td>\n",
       "      <td>0.165296</td>\n",
       "      <td>0.164141</td>\n",
       "      <td>0.196522</td>\n",
       "      <td>0.158438</td>\n",
       "      <td>0.156289</td>\n",
       "      <td>0.194182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         7        13        14        17        33        37  \\\n",
       "0  0.156041  0.290654  0.199809  0.290295  0.356657  0.307132  0.157192   \n",
       "1  0.099105  0.332776  0.119696  0.208098  0.258650  0.352134  0.101318   \n",
       "2  0.160259  0.224147  0.209884  0.213498  0.264495  0.233589  0.151807   \n",
       "3  0.139705  0.330197  0.172731  0.188332  0.243490  0.348977  0.137025   \n",
       "4  0.144930  0.312308  0.172522  0.174161  0.215116  0.328316  0.152421   \n",
       "\n",
       "         39        40        46  ...       387       388       390       398  \\\n",
       "0  0.187702  0.217832  0.374565  ...  0.309477  0.318458  0.295038  0.212476   \n",
       "1  0.130601  0.152025  0.427157  ...  0.343032  0.350165  0.319125  0.251888   \n",
       "2  0.161886  0.180539  0.275579  ...  0.364269  0.375077  0.351450  0.293468   \n",
       "3  0.159584  0.179181  0.438886  ...  0.341322  0.349891  0.321454  0.252637   \n",
       "4  0.181887  0.210446  0.382999  ...  0.197266  0.195961  0.176641  0.165296   \n",
       "\n",
       "        402       405       409       415       466  labels  \n",
       "0  0.284568  0.338188  0.244253  0.234073  0.323322       0  \n",
       "1  0.207328  0.249380  0.196100  0.174136  0.353529       0  \n",
       "2  0.241386  0.285400  0.268769  0.265217  0.382837       0  \n",
       "3  0.197635  0.243881  0.215141  0.200392  0.354787       0  \n",
       "4  0.164141  0.196522  0.158438  0.156289  0.194182       0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../reduced.csv')\n",
    "data.drop('Index', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=92))\n",
    "\n",
    "    for i in range(hp.Int('layers', 2, 6)):\n",
    "        model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
    "                                    activation=hp.Choice('act_' + str(i), ['relu', 'sigmoid'])))\n",
    "     \n",
    "    model.add(layers.Dense(6, activation=\"softmax\"))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=100,\n",
    "                     factor=3,\n",
    "                     directory='./DeepNet',\n",
    "                     project_name='Reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 01m 23s]\n",
      "val_accuracy: 0.46000000834465027\n",
      "\n",
      "Best val_accuracy So Far: 0.5076923370361328\n",
      "Total elapsed time: 00h 54m 48s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'units does not exist.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1104\\3039082851.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0moptimal\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0munits\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mdensely\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mconnected\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'units'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moptimal\u001b[0m \u001b[0mlearning\u001b[0m \u001b[0mrate\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \"\"\")\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\faces\\lib\\site-packages\\keras_tuner\\engine\\hyperparameters.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} is currently inactive.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} does not exist.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'units does not exist.'"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# print(f\"\"\"\n",
    "#     The optimal number of units in the first densely-connected layer is {best_hps.get('units')} \n",
    "#     and the optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./DeepNet\\Reduced\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 256\n",
      "act_0: relu\n",
      "units_1: 448\n",
      "act_1: relu\n",
      "learning_rate: 0.0001\n",
      "units_2: 448\n",
      "act_2: relu\n",
      "units_3: 448\n",
      "act_3: sigmoid\n",
      "units_4: 320\n",
      "act_4: sigmoid\n",
      "units_5: 64\n",
      "act_5: sigmoid\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.5076923370361328\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 448\n",
      "act_0: relu\n",
      "units_1: 384\n",
      "act_1: relu\n",
      "learning_rate: 0.0001\n",
      "units_2: 96\n",
      "act_2: relu\n",
      "units_3: 480\n",
      "act_3: relu\n",
      "units_4: 512\n",
      "act_4: relu\n",
      "units_5: 64\n",
      "act_5: relu\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 84b2dbb4ef5614a9a110196593e5dbe2\n",
      "Score: 0.49057692289352417\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 6\n",
      "units_0: 320\n",
      "act_0: relu\n",
      "units_1: 384\n",
      "act_1: relu\n",
      "learning_rate: 0.0001\n",
      "units_2: 320\n",
      "act_2: relu\n",
      "units_3: 160\n",
      "act_3: relu\n",
      "units_4: 96\n",
      "act_4: relu\n",
      "units_5: 320\n",
      "act_5: relu\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 288e2454fc01a0d0abd126d63e1bc628\n",
      "Score: 0.48884615302085876\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 448\n",
      "act_0: relu\n",
      "units_1: 384\n",
      "act_1: relu\n",
      "learning_rate: 0.0001\n",
      "units_2: 96\n",
      "act_2: relu\n",
      "units_3: 480\n",
      "act_3: relu\n",
      "units_4: 512\n",
      "act_4: relu\n",
      "units_5: 64\n",
      "act_5: relu\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.48615384101867676\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 5\n",
      "units_0: 320\n",
      "act_0: relu\n",
      "units_1: 352\n",
      "act_1: relu\n",
      "learning_rate: 0.0001\n",
      "units_2: 288\n",
      "act_2: sigmoid\n",
      "units_3: 32\n",
      "act_3: relu\n",
      "units_4: 384\n",
      "act_4: sigmoid\n",
      "units_5: 160\n",
      "act_5: sigmoid\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: d9b6b3c778c4a1683861fd64b97cbf09\n",
      "Score: 0.48288461565971375\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 4\n",
      "units_0: 416\n",
      "act_0: relu\n",
      "units_1: 384\n",
      "act_1: relu\n",
      "learning_rate: 0.001\n",
      "units_2: 224\n",
      "act_2: relu\n",
      "units_3: 480\n",
      "act_3: relu\n",
      "units_4: 160\n",
      "act_4: sigmoid\n",
      "units_5: 384\n",
      "act_5: relu\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: bc59a72e0325e2b2cfd71046f3e5e0cd\n",
      "Score: 0.48211538791656494\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 6\n",
      "units_0: 256\n",
      "act_0: relu\n",
      "units_1: 224\n",
      "act_1: relu\n",
      "learning_rate: 0.0001\n",
      "units_2: 96\n",
      "act_2: relu\n",
      "units_3: 192\n",
      "act_3: relu\n",
      "units_4: 288\n",
      "act_4: relu\n",
      "units_5: 512\n",
      "act_5: relu\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 4\n",
      "tuner/round: 3\n",
      "tuner/trial_id: e8182833c2151b5cf29d56dfada86f8e\n",
      "Score: 0.48153847455978394\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 4\n",
      "units_0: 416\n",
      "act_0: relu\n",
      "units_1: 384\n",
      "act_1: relu\n",
      "learning_rate: 0.001\n",
      "units_2: 224\n",
      "act_2: relu\n",
      "units_3: 480\n",
      "act_3: relu\n",
      "units_4: 160\n",
      "act_4: sigmoid\n",
      "units_5: 384\n",
      "act_5: relu\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 68fb300d922fc06279972ff2d7e811b2\n",
      "Score: 0.47999998927116394\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 288\n",
      "act_0: relu\n",
      "units_1: 160\n",
      "act_1: relu\n",
      "learning_rate: 0.001\n",
      "units_2: 64\n",
      "act_2: sigmoid\n",
      "units_3: 480\n",
      "act_3: relu\n",
      "units_4: 448\n",
      "act_4: relu\n",
      "units_5: 64\n",
      "act_5: relu\n",
      "tuner/epochs: 34\n",
      "tuner/initial_epoch: 12\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: dc7c230c81b473abac686743172cb920\n",
      "Score: 0.47923076152801514\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 2\n",
      "units_0: 96\n",
      "act_0: relu\n",
      "units_1: 288\n",
      "act_1: sigmoid\n",
      "learning_rate: 0.001\n",
      "units_2: 96\n",
      "act_2: sigmoid\n",
      "units_3: 256\n",
      "act_3: sigmoid\n",
      "units_4: 416\n",
      "act_4: sigmoid\n",
      "units_5: 288\n",
      "act_5: relu\n",
      "tuner/epochs: 100\n",
      "tuner/initial_epoch: 34\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: 11f2af99c02eb109a064de77e9a74a4f\n",
      "Score: 0.47923076152801514\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 256)               23808     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 448)               115136    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 448)               201152    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 2694      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 342,790\n",
      "Trainable params: 342,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(units=256, activation='relu', input_dim=92))\n",
    "model.add(layers.Dense(units=448, activation='relu'))\n",
    "model.add(layers.Dense(units=448, activation='relu'))    \n",
    "model.add(layers.Dense(6, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "650/650 [==============================] - 2s 2ms/step - loss: 1.6721 - accuracy: 0.3046 - val_loss: 1.6535 - val_accuracy: 0.3173\n",
      "Epoch 2/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.5115 - accuracy: 0.3998 - val_loss: 1.4637 - val_accuracy: 0.4073\n",
      "Epoch 3/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.4684 - accuracy: 0.4189 - val_loss: 1.4065 - val_accuracy: 0.4373\n",
      "Epoch 4/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.4480 - accuracy: 0.4282 - val_loss: 1.4248 - val_accuracy: 0.4350\n",
      "Epoch 5/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.4181 - accuracy: 0.4418 - val_loss: 1.4000 - val_accuracy: 0.4465\n",
      "Epoch 6/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.4098 - accuracy: 0.4469 - val_loss: 1.4034 - val_accuracy: 0.4433\n",
      "Epoch 7/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3958 - accuracy: 0.4510 - val_loss: 1.5730 - val_accuracy: 0.3750\n",
      "Epoch 8/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3905 - accuracy: 0.4554 - val_loss: 1.3512 - val_accuracy: 0.4642\n",
      "Epoch 9/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3803 - accuracy: 0.4587 - val_loss: 1.3907 - val_accuracy: 0.4488\n",
      "Epoch 10/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3745 - accuracy: 0.4589 - val_loss: 1.3413 - val_accuracy: 0.4663\n",
      "Epoch 11/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3702 - accuracy: 0.4645 - val_loss: 1.4082 - val_accuracy: 0.4437\n",
      "Epoch 12/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3595 - accuracy: 0.4675 - val_loss: 1.3771 - val_accuracy: 0.4531\n",
      "Epoch 13/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3633 - accuracy: 0.4667 - val_loss: 1.3554 - val_accuracy: 0.4683\n",
      "Epoch 14/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3565 - accuracy: 0.4687 - val_loss: 1.3972 - val_accuracy: 0.4381\n",
      "Epoch 15/60\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 1.3448 - accuracy: 0.4739 - val_loss: 1.3291 - val_accuracy: 0.4808\n",
      "Epoch 16/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3460 - accuracy: 0.4737 - val_loss: 1.3967 - val_accuracy: 0.4396\n",
      "Epoch 17/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3460 - accuracy: 0.4720 - val_loss: 1.3323 - val_accuracy: 0.4723\n",
      "Epoch 18/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3412 - accuracy: 0.4749 - val_loss: 1.4220 - val_accuracy: 0.4302\n",
      "Epoch 19/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3355 - accuracy: 0.4760 - val_loss: 1.3904 - val_accuracy: 0.4446\n",
      "Epoch 20/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3298 - accuracy: 0.4792 - val_loss: 1.3310 - val_accuracy: 0.4704\n",
      "Epoch 21/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3315 - accuracy: 0.4782 - val_loss: 1.3572 - val_accuracy: 0.4594\n",
      "Epoch 22/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3313 - accuracy: 0.4761 - val_loss: 1.4065 - val_accuracy: 0.4323\n",
      "Epoch 23/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3194 - accuracy: 0.4866 - val_loss: 1.3973 - val_accuracy: 0.4554\n",
      "Epoch 24/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3187 - accuracy: 0.4808 - val_loss: 1.3345 - val_accuracy: 0.4735\n",
      "Epoch 25/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3210 - accuracy: 0.4818 - val_loss: 1.3269 - val_accuracy: 0.4737\n",
      "Epoch 26/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3189 - accuracy: 0.4819 - val_loss: 1.3189 - val_accuracy: 0.4819\n",
      "Epoch 27/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2998 - accuracy: 0.4916 - val_loss: 1.3319 - val_accuracy: 0.4708\n",
      "Epoch 28/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3089 - accuracy: 0.4834 - val_loss: 1.3502 - val_accuracy: 0.4690\n",
      "Epoch 29/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3073 - accuracy: 0.4894 - val_loss: 1.3280 - val_accuracy: 0.4773\n",
      "Epoch 30/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3017 - accuracy: 0.4899 - val_loss: 1.3308 - val_accuracy: 0.4750\n",
      "Epoch 31/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2952 - accuracy: 0.4928 - val_loss: 1.3951 - val_accuracy: 0.4575\n",
      "Epoch 32/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.3015 - accuracy: 0.4914 - val_loss: 1.2976 - val_accuracy: 0.4896\n",
      "Epoch 33/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2969 - accuracy: 0.4908 - val_loss: 1.3700 - val_accuracy: 0.4594\n",
      "Epoch 34/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2907 - accuracy: 0.4956 - val_loss: 1.3041 - val_accuracy: 0.4813\n",
      "Epoch 35/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2876 - accuracy: 0.4963 - val_loss: 1.3624 - val_accuracy: 0.4638\n",
      "Epoch 36/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2864 - accuracy: 0.4977 - val_loss: 1.3127 - val_accuracy: 0.4844\n",
      "Epoch 37/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2845 - accuracy: 0.4974 - val_loss: 1.3181 - val_accuracy: 0.4810\n",
      "Epoch 38/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2825 - accuracy: 0.5002 - val_loss: 1.3186 - val_accuracy: 0.4813\n",
      "Epoch 39/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2750 - accuracy: 0.5030 - val_loss: 1.4256 - val_accuracy: 0.4463\n",
      "Epoch 40/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2805 - accuracy: 0.4983 - val_loss: 1.3013 - val_accuracy: 0.4833\n",
      "Epoch 41/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2753 - accuracy: 0.5007 - val_loss: 1.3087 - val_accuracy: 0.4817\n",
      "Epoch 42/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2746 - accuracy: 0.5012 - val_loss: 1.4159 - val_accuracy: 0.4329\n",
      "Epoch 43/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2774 - accuracy: 0.5025 - val_loss: 1.2882 - val_accuracy: 0.4912\n",
      "Epoch 44/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2663 - accuracy: 0.5053 - val_loss: 1.3090 - val_accuracy: 0.4858\n",
      "Epoch 45/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2701 - accuracy: 0.4987 - val_loss: 1.3988 - val_accuracy: 0.4440\n",
      "Epoch 46/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2612 - accuracy: 0.5043 - val_loss: 1.3067 - val_accuracy: 0.4838\n",
      "Epoch 47/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2624 - accuracy: 0.5066 - val_loss: 1.2952 - val_accuracy: 0.4885\n",
      "Epoch 48/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2607 - accuracy: 0.5055 - val_loss: 1.3085 - val_accuracy: 0.4848\n",
      "Epoch 49/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2552 - accuracy: 0.5106 - val_loss: 1.3553 - val_accuracy: 0.4713\n",
      "Epoch 50/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2482 - accuracy: 0.5120 - val_loss: 1.3449 - val_accuracy: 0.4713\n",
      "Epoch 51/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2474 - accuracy: 0.5113 - val_loss: 1.3877 - val_accuracy: 0.4569\n",
      "Epoch 52/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2446 - accuracy: 0.5085 - val_loss: 1.2968 - val_accuracy: 0.4906\n",
      "Epoch 53/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2467 - accuracy: 0.5140 - val_loss: 1.3007 - val_accuracy: 0.4915\n",
      "Epoch 54/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2396 - accuracy: 0.5142 - val_loss: 1.3167 - val_accuracy: 0.4794\n",
      "Epoch 55/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2408 - accuracy: 0.5135 - val_loss: 1.2991 - val_accuracy: 0.4877\n",
      "Epoch 56/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2336 - accuracy: 0.5164 - val_loss: 1.3144 - val_accuracy: 0.4865\n",
      "Epoch 57/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2365 - accuracy: 0.5150 - val_loss: 1.3426 - val_accuracy: 0.4781\n",
      "Epoch 58/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2362 - accuracy: 0.5148 - val_loss: 1.3437 - val_accuracy: 0.4727\n",
      "Epoch 59/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2270 - accuracy: 0.5178 - val_loss: 1.3558 - val_accuracy: 0.4688\n",
      "Epoch 60/60\n",
      "650/650 [==============================] - 1s 2ms/step - loss: 1.2289 - accuracy: 0.5174 - val_loss: 1.3417 - val_accuracy: 0.4817\n",
      "Best epoch: 53\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate= 0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=60, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyg\\anaconda3\\envs\\faces\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "\tmodel = keras.Sequential()\n",
    "\tmodel.add(layers.Dense(units=256, activation='relu', input_dim=92))\n",
    "\tmodel.add(layers.Dense(units=448, activation='relu'))\n",
    "\tmodel.add(layers.Dense(units=448, activation='relu'))    \n",
    "\tmodel.add(layers.Dense(6, activation=\"softmax\"))\n",
    "\t\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=keras.optimizers.Adam(learning_rate= 0.0001),\n",
    "\t\tloss=\"sparse_categorical_crossentropy\",\n",
    "\t\tmetrics=['accuracy'],\n",
    "\t)\n",
    "\treturn model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.510539 using {'batch_size': 20, 'epochs': 100}\n",
      "0.470882 (0.008931) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.502885 (0.006089) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.507154 (0.002638) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.463920 (0.008287) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.500846 (0.006610) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.510539 (0.002048) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.458689 (0.010281) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.499538 (0.003203) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.502192 (0.005167) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.450265 (0.001947) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.496769 (0.008012) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.509155 (0.004692) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.439111 (0.007576) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.493115 (0.009000) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.501692 (0.009289) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.426725 (0.015799) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.493538 (0.007847) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.499692 (0.011675) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andyg\\anaconda3\\envs\\faces\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "\tmodel = keras.Sequential()\n",
    "\tmodel.add(layers.Dense(units=256, activation='relu', input_dim=92))\n",
    "\tmodel.add(layers.Dense(units=448, activation='relu'))\n",
    "\tmodel.add(layers.Dense(units=448, activation='relu'))    \n",
    "\tmodel.add(layers.Dense(6, activation=\"softmax\"))\n",
    "\t\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=optimizer,\n",
    "\t\tloss=\"sparse_categorical_crossentropy\",\n",
    "\t\tmetrics=['accuracy'],\n",
    "\t)\n",
    "\treturn model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=20, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.507424 using {'optimizer': 'Adamax'}\n",
      "0.493576 (0.009201) with: {'optimizer': 'SGD'}\n",
      "0.435610 (0.022329) with: {'optimizer': 'RMSprop'}\n",
      "0.437918 (0.004268) with: {'optimizer': 'Adagrad'}\n",
      "0.266559 (0.003022) with: {'optimizer': 'Adadelta'}\n",
      "0.481345 (0.012709) with: {'optimizer': 'Adam'}\n",
      "0.507424 (0.007970) with: {'optimizer': 'Adamax'}\n",
      "0.489961 (0.006561) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "975/975 [==============================] - 4s 4ms/step - loss: 1.7449 - accuracy: 0.2652 - val_loss: 1.7308 - val_accuracy: 0.2617\n",
      "Epoch 2/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.7208 - accuracy: 0.2722 - val_loss: 1.7031 - val_accuracy: 0.2920\n",
      "Epoch 3/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.6874 - accuracy: 0.2952 - val_loss: 1.6588 - val_accuracy: 0.3323\n",
      "Epoch 4/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.6424 - accuracy: 0.3449 - val_loss: 1.6209 - val_accuracy: 0.3178\n",
      "Epoch 5/100\n",
      "975/975 [==============================] - 4s 4ms/step - loss: 1.5985 - accuracy: 0.3749 - val_loss: 1.5709 - val_accuracy: 0.3865\n",
      "Epoch 6/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.5614 - accuracy: 0.3946 - val_loss: 1.5353 - val_accuracy: 0.4086\n",
      "Epoch 7/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.5315 - accuracy: 0.4091 - val_loss: 1.5308 - val_accuracy: 0.4185\n",
      "Epoch 8/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.5070 - accuracy: 0.4156 - val_loss: 1.4854 - val_accuracy: 0.4263\n",
      "Epoch 9/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.4871 - accuracy: 0.4193 - val_loss: 1.4660 - val_accuracy: 0.4366\n",
      "Epoch 10/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.4687 - accuracy: 0.4273 - val_loss: 1.4536 - val_accuracy: 0.4392\n",
      "Epoch 11/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.4532 - accuracy: 0.4323 - val_loss: 1.4448 - val_accuracy: 0.4402\n",
      "Epoch 12/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.4416 - accuracy: 0.4352 - val_loss: 1.4360 - val_accuracy: 0.4318\n",
      "Epoch 13/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.4286 - accuracy: 0.4416 - val_loss: 1.4161 - val_accuracy: 0.4494\n",
      "Epoch 14/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.4177 - accuracy: 0.4459 - val_loss: 1.4069 - val_accuracy: 0.4562\n",
      "Epoch 15/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.4080 - accuracy: 0.4483 - val_loss: 1.4141 - val_accuracy: 0.4365\n",
      "Epoch 16/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.4021 - accuracy: 0.4512 - val_loss: 1.3826 - val_accuracy: 0.4615\n",
      "Epoch 17/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.3938 - accuracy: 0.4560 - val_loss: 1.3780 - val_accuracy: 0.4612\n",
      "Epoch 18/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.3866 - accuracy: 0.4576 - val_loss: 1.3754 - val_accuracy: 0.4592\n",
      "Epoch 19/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.3808 - accuracy: 0.4585 - val_loss: 1.4267 - val_accuracy: 0.4238\n",
      "Epoch 20/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.3753 - accuracy: 0.4594 - val_loss: 1.3791 - val_accuracy: 0.4568\n",
      "Epoch 21/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3701 - accuracy: 0.4630 - val_loss: 1.3683 - val_accuracy: 0.4658\n",
      "Epoch 22/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3695 - accuracy: 0.4647 - val_loss: 1.3669 - val_accuracy: 0.4623\n",
      "Epoch 23/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3643 - accuracy: 0.4667 - val_loss: 1.3516 - val_accuracy: 0.4698\n",
      "Epoch 24/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3574 - accuracy: 0.4687 - val_loss: 1.3768 - val_accuracy: 0.4645\n",
      "Epoch 25/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3567 - accuracy: 0.4713 - val_loss: 1.3446 - val_accuracy: 0.4755\n",
      "Epoch 26/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3534 - accuracy: 0.4717 - val_loss: 1.3382 - val_accuracy: 0.4752\n",
      "Epoch 27/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3488 - accuracy: 0.4749 - val_loss: 1.3479 - val_accuracy: 0.4738\n",
      "Epoch 28/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3472 - accuracy: 0.4747 - val_loss: 1.3477 - val_accuracy: 0.4702\n",
      "Epoch 29/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3432 - accuracy: 0.4773 - val_loss: 1.3308 - val_accuracy: 0.4782\n",
      "Epoch 30/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3442 - accuracy: 0.4731 - val_loss: 1.3594 - val_accuracy: 0.4675\n",
      "Epoch 31/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3387 - accuracy: 0.4782 - val_loss: 1.3375 - val_accuracy: 0.4849\n",
      "Epoch 32/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3396 - accuracy: 0.4804 - val_loss: 1.3343 - val_accuracy: 0.4795\n",
      "Epoch 33/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3347 - accuracy: 0.4773 - val_loss: 1.3380 - val_accuracy: 0.4806\n",
      "Epoch 34/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3327 - accuracy: 0.4775 - val_loss: 1.3434 - val_accuracy: 0.4777\n",
      "Epoch 35/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3316 - accuracy: 0.4783 - val_loss: 1.3261 - val_accuracy: 0.4814\n",
      "Epoch 36/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3316 - accuracy: 0.4807 - val_loss: 1.3208 - val_accuracy: 0.4823\n",
      "Epoch 37/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3304 - accuracy: 0.4840 - val_loss: 1.3188 - val_accuracy: 0.4835\n",
      "Epoch 38/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3253 - accuracy: 0.4845 - val_loss: 1.3273 - val_accuracy: 0.4858\n",
      "Epoch 39/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3246 - accuracy: 0.4829 - val_loss: 1.3170 - val_accuracy: 0.4909\n",
      "Epoch 40/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3262 - accuracy: 0.4804 - val_loss: 1.3561 - val_accuracy: 0.4686\n",
      "Epoch 41/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3192 - accuracy: 0.4863 - val_loss: 1.3121 - val_accuracy: 0.4889\n",
      "Epoch 42/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3197 - accuracy: 0.4877 - val_loss: 1.3273 - val_accuracy: 0.4808\n",
      "Epoch 43/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3188 - accuracy: 0.4840 - val_loss: 1.3175 - val_accuracy: 0.4900\n",
      "Epoch 44/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3199 - accuracy: 0.4846 - val_loss: 1.3153 - val_accuracy: 0.4872\n",
      "Epoch 45/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3184 - accuracy: 0.4877 - val_loss: 1.3153 - val_accuracy: 0.4851\n",
      "Epoch 46/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3138 - accuracy: 0.4886 - val_loss: 1.3260 - val_accuracy: 0.4860\n",
      "Epoch 47/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3182 - accuracy: 0.4858 - val_loss: 1.3065 - val_accuracy: 0.4942\n",
      "Epoch 48/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3146 - accuracy: 0.4880 - val_loss: 1.3136 - val_accuracy: 0.4943\n",
      "Epoch 49/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3105 - accuracy: 0.4898 - val_loss: 1.3063 - val_accuracy: 0.4945\n",
      "Epoch 50/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3073 - accuracy: 0.4917 - val_loss: 1.3037 - val_accuracy: 0.4963\n",
      "Epoch 51/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3081 - accuracy: 0.4907 - val_loss: 1.3002 - val_accuracy: 0.4932\n",
      "Epoch 52/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3093 - accuracy: 0.4933 - val_loss: 1.3033 - val_accuracy: 0.4942\n",
      "Epoch 53/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3039 - accuracy: 0.4937 - val_loss: 1.3008 - val_accuracy: 0.4954\n",
      "Epoch 54/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3047 - accuracy: 0.4922 - val_loss: 1.2967 - val_accuracy: 0.4985\n",
      "Epoch 55/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3030 - accuracy: 0.4922 - val_loss: 1.2979 - val_accuracy: 0.4949\n",
      "Epoch 56/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.3026 - accuracy: 0.4903 - val_loss: 1.3143 - val_accuracy: 0.4918\n",
      "Epoch 57/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.3008 - accuracy: 0.4932 - val_loss: 1.3059 - val_accuracy: 0.4986\n",
      "Epoch 58/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.3003 - accuracy: 0.4938 - val_loss: 1.3209 - val_accuracy: 0.4811\n",
      "Epoch 59/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.3001 - accuracy: 0.4942 - val_loss: 1.2913 - val_accuracy: 0.4992\n",
      "Epoch 60/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.2987 - accuracy: 0.4930 - val_loss: 1.2989 - val_accuracy: 0.4952\n",
      "Epoch 61/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.2995 - accuracy: 0.4952 - val_loss: 1.3439 - val_accuracy: 0.4786\n",
      "Epoch 62/100\n",
      "975/975 [==============================] - 2s 3ms/step - loss: 1.2962 - accuracy: 0.4945 - val_loss: 1.2977 - val_accuracy: 0.4963\n",
      "Epoch 63/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.2963 - accuracy: 0.4936 - val_loss: 1.2978 - val_accuracy: 0.5015: 0s - loss: 1.2957 - \n",
      "Epoch 64/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2949 - accuracy: 0.4952 - val_loss: 1.2881 - val_accuracy: 0.5002\n",
      "Epoch 65/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2937 - accuracy: 0.4965 - val_loss: 1.2966 - val_accuracy: 0.4969\n",
      "Epoch 66/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2902 - accuracy: 0.4979 - val_loss: 1.3228 - val_accuracy: 0.4854\n",
      "Epoch 67/100\n",
      "975/975 [==============================] - 2s 3ms/step - loss: 1.2945 - accuracy: 0.4959 - val_loss: 1.2849 - val_accuracy: 0.5031\n",
      "Epoch 68/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.2935 - accuracy: 0.4971 - val_loss: 1.2895 - val_accuracy: 0.5043\n",
      "Epoch 69/100\n",
      "975/975 [==============================] - 2s 3ms/step - loss: 1.2924 - accuracy: 0.4935 - val_loss: 1.2987 - val_accuracy: 0.5017\n",
      "Epoch 70/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.2881 - accuracy: 0.5000 - val_loss: 1.3204 - val_accuracy: 0.4892\n",
      "Epoch 71/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2884 - accuracy: 0.4944 - val_loss: 1.2958 - val_accuracy: 0.5045\n",
      "Epoch 72/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2873 - accuracy: 0.4987 - val_loss: 1.3068 - val_accuracy: 0.5011\n",
      "Epoch 73/100\n",
      "975/975 [==============================] - 2s 3ms/step - loss: 1.2878 - accuracy: 0.4999 - val_loss: 1.2799 - val_accuracy: 0.5075\n",
      "Epoch 74/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2834 - accuracy: 0.5026 - val_loss: 1.2880 - val_accuracy: 0.5026\n",
      "Epoch 75/100\n",
      "975/975 [==============================] - 2s 3ms/step - loss: 1.2846 - accuracy: 0.5010 - val_loss: 1.2830 - val_accuracy: 0.5052\n",
      "Epoch 76/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2854 - accuracy: 0.4994 - val_loss: 1.2977 - val_accuracy: 0.5038\n",
      "Epoch 77/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2834 - accuracy: 0.5008 - val_loss: 1.2768 - val_accuracy: 0.5085\n",
      "Epoch 78/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2861 - accuracy: 0.4993 - val_loss: 1.2760 - val_accuracy: 0.5026\n",
      "Epoch 79/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2804 - accuracy: 0.4992 - val_loss: 1.2921 - val_accuracy: 0.4989\n",
      "Epoch 80/100\n",
      "975/975 [==============================] - 2s 3ms/step - loss: 1.2816 - accuracy: 0.5020 - val_loss: 1.2771 - val_accuracy: 0.5111\n",
      "Epoch 81/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2811 - accuracy: 0.4995 - val_loss: 1.2894 - val_accuracy: 0.4923\n",
      "Epoch 82/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2783 - accuracy: 0.5045 - val_loss: 1.2810 - val_accuracy: 0.5040\n",
      "Epoch 83/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2764 - accuracy: 0.5036 - val_loss: 1.2886 - val_accuracy: 0.5006\n",
      "Epoch 84/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2762 - accuracy: 0.5039 - val_loss: 1.3105 - val_accuracy: 0.4911\n",
      "Epoch 85/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.2752 - accuracy: 0.5024 - val_loss: 1.2759 - val_accuracy: 0.5080\n",
      "Epoch 86/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2749 - accuracy: 0.5022 - val_loss: 1.2699 - val_accuracy: 0.5051\n",
      "Epoch 87/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2752 - accuracy: 0.5035 - val_loss: 1.3065 - val_accuracy: 0.4974\n",
      "Epoch 88/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2722 - accuracy: 0.5050 - val_loss: 1.2689 - val_accuracy: 0.5077\n",
      "Epoch 89/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2736 - accuracy: 0.5034 - val_loss: 1.2714 - val_accuracy: 0.5051\n",
      "Epoch 90/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2725 - accuracy: 0.5035 - val_loss: 1.2783 - val_accuracy: 0.5062\n",
      "Epoch 91/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2728 - accuracy: 0.5026 - val_loss: 1.3156 - val_accuracy: 0.4942\n",
      "Epoch 92/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2688 - accuracy: 0.5060 - val_loss: 1.2702 - val_accuracy: 0.5074\n",
      "Epoch 93/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2701 - accuracy: 0.5035 - val_loss: 1.2751 - val_accuracy: 0.5055\n",
      "Epoch 94/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2671 - accuracy: 0.5057 - val_loss: 1.2788 - val_accuracy: 0.5125\n",
      "Epoch 95/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.2678 - accuracy: 0.5039 - val_loss: 1.2637 - val_accuracy: 0.5098\n",
      "Epoch 96/100\n",
      "975/975 [==============================] - 2s 2ms/step - loss: 1.2707 - accuracy: 0.5059 - val_loss: 1.2635 - val_accuracy: 0.5089\n",
      "Epoch 97/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.2676 - accuracy: 0.5065 - val_loss: 1.2724 - val_accuracy: 0.5089\n",
      "Epoch 98/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.2666 - accuracy: 0.5033 - val_loss: 1.2673 - val_accuracy: 0.5057\n",
      "Epoch 99/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.2640 - accuracy: 0.5042 - val_loss: 1.2908 - val_accuracy: 0.5075\n",
      "Epoch 100/100\n",
      "975/975 [==============================] - 3s 3ms/step - loss: 1.2636 - accuracy: 0.5078 - val_loss: 1.2703 - val_accuracy: 0.5049\n"
     ]
    }
   ],
   "source": [
    "logdir=\"./logs/optimizer\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=1) \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(units=256, activation='relu', input_dim=92))\n",
    "model.add(layers.Dense(units=488, activation='relu'))\n",
    "model.add(layers.Dense(units=488, activation='relu'))    \n",
    "model.add(layers.Dense(6, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "\toptimizer=keras.optimizers.Adamax(learning_rate=0.0001),\n",
    "\tloss=\"sparse_categorical_crossentropy\",\n",
    "\tmetrics=['accuracy'],\n",
    ")\n",
    "\n",
    "batch_size = 20\n",
    "history = model.fit(\n",
    "    x_train, # input\n",
    "    y_train, # output\n",
    "    batch_size=batch_size,\n",
    "    verbose=1, \n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions = keras.backend.argmax(\n",
    "    predictions,\n",
    "    axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4950769230769231"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 227,   19,  149,  195,  242,   44],\n",
       "       [  83,   50,  160,  234,  327,  111],\n",
       "       [  30,    7, 1401,  127,  120,   28],\n",
       "       [  71,   16,   75,  605,  376,   28],\n",
       "       [  59,   23,  122,  263,  544,   12],\n",
       "       [  33,   31,   88,  166,   43,  391]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2156adda188>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(confusion_matrix(y_test, predictions))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25913242, 0.05181347, 0.8178634 , 0.51665243, 0.53176931,\n",
       "       0.51994681])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, predictions, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45129225, 0.34246575, 0.70225564, 0.38050314, 0.32929782,\n",
       "       0.63680782])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, predictions, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43b097dcbb7d9cb0e64103649a6a6f2c394047a8ddff41dd856c2f5bc9a53d21"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('faces': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
